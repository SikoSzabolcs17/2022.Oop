{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SikoSzabolcs17/2022.Oop/blob/master/pkp_lab1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Labor 1\n",
        "\n",
        "# Bevezetés a CUDA GPU programozásba\n",
        "\n",
        "## Mi a párhuzamos programozás?\n",
        "\n",
        "A párhuzamos programozás olyan programozási paradigma, ahol több számítási feladat egyidejűleg, egymással párhuzamosan fut. Hagyományos, szekvenciális programozás esetén a program utasításai egymás után, lépésről lépésre hajtódnak végre. Ezzel szemben a párhuzamos programozás lehetővé teszi, hogy több utasítás egyidejűleg fusson.\n",
        "\n",
        "## Miért van szükség párhuzamos programozásra?\n",
        "\n",
        "A processzorteljesítmény növelése az évek során elérte fizikai korlátait (órajel, hőtermelés). Az egymagos processzorok teljesítménye nem növelhető a végtelenségig, így többmagos processzorokat kezdtek gyártani. Bizonyos feladatok természetüknél fogva párhuzamosíthatók (pl. képfeldolgozás, mátrixműveletek, szimulációk), amelyek hatékonyan felgyorsíthatók párhuzamos feldolgozással.\n",
        "\n",
        "## GPU-k és a CUDA szerepe\n",
        "\n",
        "A grafikus processzorok (GPU-k) eredetileg a számítógépes grafikához készültek, de felismerték, hogy bizonyos számítási feladatok (különösen azok, amelyek sok adaton ugyanazt a műveletet végzik) sokkal gyorsabban futhatnak rajtuk. A GPU-k több ezer egyszerűbb számítási magot tartalmaznak, szemben a CPU-k néhány komplex magjával.\n",
        "\n",
        "A [GPGPU](https://www.gigabyte.com/Glossary/gpgpu) rövidítés a \"General Purpose Graphics Processing Unit\"-ra utal, ami egy olyan számítási technológia, amely során a grafikus kártyák (GPU-k) számítási kapacitását használjuk általános célú számítások végrehajtására. Mint láttuk, a GPU-k eredetileg kifejezetten grafikus feladatok hatékony megoldására lettek tervezve, mint például a képfeldolgozás vagy 3D grafika. Azonban, az elmúlt években a GPU-k egyre inkább beépültek az általános célú számítások világába is.\n",
        "\n",
        "A GPGPU technológia alkalmazása lehetővé teszi, hogy a GPU-k nagy számítási kapacitását felhasználják olyan feladatok elvégzésére, mint például a gépi tanulás, a kriptográfiai műveletek, a tudományos szimulációk vagy a nagy adathalmazok feldolgozása. A GPGPU technológia használata jelentősen felgyorsíthatja ezeket a számítási feladatokat, és csökkentheti azok elvégzésének idejét.\n",
        "\n",
        "Az NVIDIA 2007-ben bemutatta a CUDA (Compute Unified Device Architecture) platformot, amely lehetővé teszi a programozók számára, hogy a GPU-kat általános célú számításokra is használhassák (GPGPU - General-Purpose computing on Graphics Processing Units).\n",
        "\n",
        "## Heterogén párhuzamos programozás\n",
        "\n",
        "A CUDA programozást heterogén párhuzamos programozásnak is nevezik, mert:\n",
        "\n",
        "1. **Heterogén rendszer**: A CPU (host) és a GPU (device) együttműködve oldják meg a feladatot\n",
        "2. **Különböző architektúrák**: A CPU és a GPU eltérő architektúrával és memóriarendszerrel rendelkezik\n",
        "3. **Eltérő feladatkörök**: A CPU általában a szekvenciális részeket, a GPU a párhuzamosítható részeket hajtja végre\n",
        "\n"
      ],
      "metadata": {
        "id": "-vk-2uPuPL6E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CUDA Runtime API\n",
        "\n",
        "\n",
        "A [CUDA Runtime API](https://docs.nvidia.com/cuda/cuda-runtime-api/index.html) egy függvénykönyvtárból és a C++ szintaxis egyszerű kiegészítéséből áll.\n",
        "\n",
        "A CUDA programokat `*.cu` (nem `*.c` vagy `*.cpp`) kiterjesztésű állományokban írjuk. Mint meglátjuk, alapvetően C++ kódot írünk, melyet néha kiegészíthetünk gyorsítón futtatandó programrészletekkel, úgynevezett \"CUDA kernelekkel\".\n",
        "\n",
        "Az alábbi kódrészlet egy tökéletesen működő CUDA program, csak éppenséggel még nem tartalmaz gyorsító specifikus kódot.\n",
        "\n",
        "```cpp\n",
        "#include <iostream>\n",
        "\n",
        "int main(int argc, char** argv)\n",
        "{\n",
        "    std::cout << \"Hello World!\" << std::endl;\n",
        "    return 0;\n",
        "}\n",
        "```\n",
        "\n",
        "\n",
        "Ha a programunkban szeretnénk kihasználni a GPU számítási kapacitását lehetőségeit is, akkor GPU kódot is írnunk kell. Ez a számításokhoz szükséges adatokat előkészíti, átmásolja, meghívja a GPU kernelt, majd az adatokat visszamásolja. A CUDA forráskódok általában keverten tartalmazzák a CPU, és GPU kódokat.\n",
        "\n",
        "A GPU-n futó számítást úgynevezett a fentebb említett kernel függvények megadásával tudjuk megvalósítani. Ezek a `__global__` előtaggal rendelkező függvények.\n",
        "\n",
        "### Kompilálás és futtatás\n",
        "\n",
        "A CUDA (`*.cu` kiterjesztésű) programjaink kompilálásához, használjuk a következő parancsot:  \n",
        "\n",
        "```\n",
        "!nvcc mysurcefile.cu -o programname\n",
        "```\n",
        "\n",
        "majd sikeres kompilálás esetében, futtatáshoz:\n",
        "```\n",
        "!./programname\n",
        "```"
      ],
      "metadata": {
        "id": "ikVGiziWBV53"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CUDA program általános szerkezete\n",
        "\n",
        "A CUDA programok speciális felépítéssel rendelkeznek, ami a heterogén rendszer sajátosságaiból adódik. Az alábbiakban megnézzük a tipikus CUDA program szerkezetét és a főbb lépéseket.\n",
        "\n",
        "## 1. Program inicializálás és feladatmeghatározás\n",
        "\n",
        "Minden CUDA program a host (CPU) oldalon kezdődik, ahol:\n",
        "- Meghatározzuk a feladat méretét (pl. feldolgozandó elemek száma)\n",
        "- Inicializáljuk a bemeneti adatokat\n",
        "- Kiszámoljuk a memória igényeket\n",
        "\n",
        "```c\n",
        "int n = 1000000;  // Elemek száma\n",
        "size_t size = n * sizeof(float);  // Szükséges memória mérete bájtokban\n",
        "```\n",
        "\n",
        "## 2. Memória kezelés a heterogén rendszerben\n",
        "\n",
        "Kulcsfontosságú megérteni, hogy a CPU és GPU külön memóriaterülettel rendelkezik, így explicit memóriakezelésre van szükség:\n",
        "\n",
        "### a) Host memória foglalás (CPU oldal)\n",
        "```c\n",
        "float *h_input = (float*)malloc(size);\n",
        "float *h_output = (float*)malloc(size);\n",
        "\n",
        "// Adatok inicializálása\n",
        "for (int i = 0; i < n; i++) {\n",
        "    h_input[i] = rand() / (float)RAND_MAX;\n",
        "}\n",
        "```\n",
        "\n",
        "### b) Device memória foglalás (GPU oldal)\n",
        "```c\n",
        "float *d_input = NULL;\n",
        "float *d_output = NULL;\n",
        "cudaMalloc((void**)&d_input, size);\n",
        "cudaMalloc((void**)&d_output, size);\n",
        "```\n",
        "\n",
        "### c) Adatok másolása host-ról device-ra\n",
        "```c\n",
        "cudaMemcpy(d_input, h_input, size, cudaMemcpyHostToDevice);\n",
        "```\n",
        "\n",
        "## 3. Kernel definíció\n",
        "\n",
        "A kernel a GPU-n futó függvény, amelyet a `__global__` kulcsszóval jelölünk:\n",
        "\n",
        "```c\n",
        "__global__ void processData(float *input, float *output, int n) {\n",
        "    // Egyedi szálazonosító számítása\n",
        "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    \n",
        "    // Ellenőrzés, hogy a szál érvényes adatelemen dolgozik-e\n",
        "    if (idx < n) {\n",
        "        // Tényleges munka elvégzése (példa: érték duplázása)\n",
        "        output[idx] = 2.0f * input[idx];\n",
        "    }\n",
        "}\n",
        "```\n",
        "\n",
        "## 4. Végrehajtási konfiguráció és kernel indítás\n",
        "\n",
        "A kernel indításakor meg kell határozni a végrehajtási konfigurációt (hogyan szerveződnek a szálak blokkokba, a blokkok egy rácsba (grid)):\n",
        "\n",
        "```c\n",
        "// Blokkméret meghatározása (szálak száma blokkonként)\n",
        "int threadsPerBlock = 256;\n",
        "\n",
        "// Blokkok számának kiszámítása\n",
        "// Felfelé kerekítünk, hogy minden adatelemhez jusson szál\n",
        "int blocksPerGrid = (n + threadsPerBlock - 1) / threadsPerBlock;\n",
        "\n",
        "// Kernel indítása a megadott konfigurációval\n",
        "processData<<<blocksPerGrid, threadsPerBlock>>>(d_input, d_output, n);\n",
        "\n",
        "// Aszinkron végrehajtás - megvárjuk a befejezést\n",
        "cudaDeviceSynchronize();\n",
        "```\n",
        "\n",
        "## 5. Eredmények visszaolvasása\n",
        "\n",
        "A feldolgozás után az eredményeket vissza kell másolni a GPU-ról a CPU memóriába:\n",
        "\n",
        "```c\n",
        "cudaMemcpy(h_output, d_output, size, cudaMemcpyDeviceToHost);\n",
        "```\n",
        "\n",
        "## 6. Eredmények feldolgozása és erőforrások felszabadítása\n",
        "\n",
        "A CPU oldalon feldolgozzuk az eredményeket, majd felszabadítjuk a lefoglalt erőforrásokat:\n",
        "\n",
        "```c\n",
        "// Eredmények feldolgozása (pl. ellenőrzés)\n",
        "for (int i = 0; i < 10; i++) {\n",
        "    printf(\"Input: %f, Output: %f\\n\", h_input[i], h_output[i]);\n",
        "}\n",
        "\n",
        "// Erőforrások felszabadítása\n",
        "cudaFree(d_input);\n",
        "cudaFree(d_output);\n",
        "free(h_input);\n",
        "free(h_output);\n",
        "```\n",
        "\n",
        "## 7. Hibakezelés (jó gyakorlat)\n",
        "\n",
        "A CUDA API hívások hibakódot adnak vissza, amit érdemes ellenőrizni:\n",
        "\n",
        "```c\n",
        "cudaError_t err = cudaMemcpy(d_input, h_input, size, cudaMemcpyHostToDevice);\n",
        "if (err != cudaSuccess) {\n",
        "    printf(\"CUDA error: %s\\n\", cudaGetErrorString(err));\n",
        "    // Hibakezelés...\n",
        "}\n",
        "```\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "hz1yiTaVTck0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Szálazonosító számítása a CUDA-ban\n",
        "\n",
        "### Egyedi szálazonosítók működése\n",
        "\n",
        "A CUDA architektúrában minden szálnak szüksége van egy egyedi azonosítóra, hogy tudja, melyik adatelemen kell dolgoznia. Ez az azonosító kiszámítása kulcsfontosságú a párhuzamos végrehajtás során. A CUDA hierarchikus modellben gondolkodik: a szálak blokkokba vannak szervezve, a blokkok pedig rácsot (grid) alkotnak.\n",
        "\n",
        "Az egyedi globális szálazonosító (global thread ID) kiszámítása a következő képlettel történik 1D szervezás esetében:\n",
        "\n",
        "```\n",
        "globalId = blockIdx.x * blockDim.x + threadIdx.x\n",
        "```\n",
        "\n",
        "Ahol:\n",
        "- `blockIdx.x`: Az aktuális blokk indexe a rácsban\n",
        "- `blockDim.x`: A blokkon belüli szálak száma (szálak per blokk)\n",
        "- `threadIdx.x`: A szál indexe a blokkon belül\n",
        "\n",
        "### Példák az 1D azonosító számításra\n",
        "\n",
        "- Ha 2 blokkunk van, egyenként 3 szállal:\n",
        "  - 0. blokk, 0. szál: `0 * 3 + 0 = 0`\n",
        "  - 0. blokk, 1. szál: `0 * 3 + 1 = 1`\n",
        "  - 0. blokk, 2. szál: `0 * 3 + 2 = 2`\n",
        "  - 1. blokk, 0. szál: `1 * 3 + 0 = 3`\n",
        "  - 1. blokk, 1. szál: `1 * 3 + 1 = 4`\n",
        "  - 1. blokk, 2. szál: `1 * 3 + 2 = 5`\n",
        "\n",
        "\n",
        "Ez a számítási modell biztosítja, hogy minden szál pontosan tudja, melyik adatelemen kell dolgoznia, függetlenül attól, hogy hány blokkot és szálat használunk a párhuzamos végrehajtáshoz.\n",
        "\n",
        "\n",
        "Késobbiekben majd megltájuk, hogy például kétdimenziós (pl. mátrixműveleteknél) szervezés esetében is tudunk mindig linearizálni, egyedi azonosítot számítani:\n",
        "\n",
        "```c\n",
        "int row = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "int col = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "int idx = row * width + col;  // Linearizált index\n",
        "```\n"
      ],
      "metadata": {
        "id": "MK-ZXdmySc9p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Példa: Teljes CUDA program a vektorok összeadására\n",
        "\n",
        "Két vektor elemeinek összegzése párhuzamosan CUDA-val:\n",
        "\n",
        "```c\n",
        "#include <stdio.h>\n",
        "#include <cuda_runtime.h>\n",
        "\n",
        "// GPU kernel - minden szál egy elemet dolgoz fel\n",
        "__global__ void vectorAdd(int *a, int *b, int *c, int n) {\n",
        "    int i = blockDim.x * blockIdx.x + threadIdx.x;\n",
        "    if (i < n) {\n",
        "        c[i] = a[i] + b[i];\n",
        "    }\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    int n = 1000;\n",
        "    int size = n * sizeof(int);\n",
        "    \n",
        "    // Host memória foglalása\n",
        "    int *h_a = (int *)malloc(size);\n",
        "    int *h_b = (int *)malloc(size);\n",
        "    int *h_c = (int *)malloc(size);\n",
        "    \n",
        "    // Vektorok inicializálása\n",
        "    for (int i = 0; i < n; i++) {\n",
        "        h_a[i] = i;\n",
        "        h_b[i] = i;\n",
        "    }\n",
        "    \n",
        "    // Device memória foglalása\n",
        "    int *d_a, *d_b, *d_c;\n",
        "    cudaMalloc(&d_a, size);\n",
        "    cudaMalloc(&d_b, size);\n",
        "    cudaMalloc(&d_c, size);\n",
        "    \n",
        "    // Adatok másolása a host-ról a device-ra\n",
        "    cudaMemcpy(d_a, h_a, size, cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_b, h_b, size, cudaMemcpyHostToDevice);\n",
        "    \n",
        "    // Kernel indítása 256 szállal blokkonként\n",
        "    int threadsPerBlock = 256;\n",
        "    int blocksPerGrid = (n + threadsPerBlock - 1) / threadsPerBlock;\n",
        "    vectorAdd<<<blocksPerGrid, threadsPerBlock>>>(d_a, d_b, d_c, n);\n",
        "    \n",
        "    // Eredmény visszamásolása a device-ról a host-ra\n",
        "    cudaMemcpy(h_c, d_c, size, cudaMemcpyDeviceToHost);\n",
        "    \n",
        "    // Eredmény ellenőrzése\n",
        "    for (int i = 0; i < 10; i++) {\n",
        "        printf(\"%d + %d = %d\\n\", h_a[i], h_b[i], h_c[i]);\n",
        "    }\n",
        "    \n",
        "    // Memória felszabadítása\n",
        "    cudaFree(d_a);\n",
        "    cudaFree(d_b);\n",
        "    cudaFree(d_c);\n",
        "    free(h_a);\n",
        "    free(h_b);\n",
        "    free(h_c);\n",
        "    \n",
        "    return 0;\n",
        "}\n",
        "```\n",
        "\n",
        "A CUDA programozás alapelvei a példában fellelhetőek:\n",
        "1. Szétválasztjuk a kódot CPU (host) és GPU (device) részekre\n",
        "2. A GPU kódot speciális `__global__` kulcsszóval jelöljük (kernel)\n",
        "3. Memóriát foglalunk mindkét eszközön, és explicit másolással kommunikálunk\n",
        "4. Meghatározzuk a párhuzamosítás szintjét (hány blokk és hány szál/blokk)\n",
        "\n",
        "A CUDA előnye, hogy C nyelvi környezetben programozhatunk, minimális nyelvi kiterjesztésekkel, miközben kihasználjuk a GPU-k párhuzamos feldolgozási képességeit."
      ],
      "metadata": {
        "id": "xCxjHelCPdjq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Google Colaboratory\n",
        "\n",
        "A Google Colaboratory (röviden Colab) egy ingyenes online platform, amely lehetővé teszi a felhasználók számára a (főleg) Python programozási nyelv interaktív környezetében történő munkavégzését. Az egyik fő előnye, hogy ingyenes GPU és TPU (Tensor Processing Unit) számítási erőforrásokat biztosít a felhasználók számára, azzal a cállal, hogy lehetővé tegye a nagyobb adatméretű és bonyolultabb gépi tanulási és adatelemzési feladatok végrehajtását.\n",
        "\n",
        "Az GPU erőforrások igénybevétele érdekében, a felhasználóknak a futásidejű környezet típusát kell áttálítsa. Ehhez, a `Runtime/Change runtime` menűpontban válasszuk ki, hogy `GPU`."
      ],
      "metadata": {
        "id": "RDNbKVlU9cMg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A `GPU` elérhetőségét teszteln tudjuk a következő kóddal:"
      ],
      "metadata": {
        "id": "LH1eSOFi_g_o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5j03fCHP_PoQ",
        "outputId": "ff4509b1-3aca-4a03-a31f-ab35cd761614"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A Nvidia kompájler verziójának lekérése:"
      ],
      "metadata": {
        "id": "SxGnDTAs_51e"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0hxdSMs37ZtV",
        "outputId": "b5c3909a-e3e4-4501-e141-7e50fbd903f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2024 NVIDIA Corporation\n",
            "Built on Thu_Jun__6_02:18:23_PDT_2024\n",
            "Cuda compilation tools, release 12.5, V12.5.82\n",
            "Build cuda_12.5.r12.5/compiler.34385749_0\n"
          ]
        }
      ],
      "source": [
        "!nvcc --version"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A kód cellákkban csak Python kód futtatható direkt modon. Ezért, [%%writefile magic](https://ipython.readthedocs.io/en/stable/interactive/magics.html) parancsal fogjuk kiírni a lemezre a programjainkat, majd ezeket más kódcellákban kompiláljuk és futtatjuk.\n",
        "\n",
        "Például, az alábbi példaprogram GPU-n végzi el két szám összeadását."
      ],
      "metadata": {
        "id": "6BAs6WrnAA7b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile vecadd.cu\n",
        "#include <cuda.h>\n",
        "#include <stdio.h>\n",
        "\n",
        "__global__ void add(int a, int b, int* c)\n",
        "{\n",
        "    *c = a + b;\n",
        "    return;\n",
        "}\n",
        "\n",
        "int main(int argc, char** argv)\n",
        "{\n",
        "    int c;\n",
        "    int* dev_c;\n",
        "\n",
        "\t  //memória foglalás a GPU-n\n",
        "    cudaMalloc((void**)&dev_c, sizeof(int) );\n",
        "\n",
        "    add<<<1,1>>>(1, 2, dev_c);\n",
        "\n",
        "    cudaMemcpy(&c, dev_c, sizeof(int), cudaMemcpyDeviceToHost);\n",
        "\n",
        "    printf(\"a + b = %d\\n\", c);\n",
        "\n",
        "    //lefolglat memória felszabadítása\n",
        "    cudaFree(dev_c);\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HL9JO5bt7hrW",
        "outputId": "476836fa-5851-4d9d-db30-772005936dae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing vecadd.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "És íme meg is jelenik a `vecadd.cu` állomány:"
      ],
      "metadata": {
        "id": "um6CYayyAxIY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gsq0-uVN9Gbo",
        "outputId": "4c426c45-c873-4de1-eccf-77f931798911"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sample_data  vecadd.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Kompilálás:"
      ],
      "metadata": {
        "id": "lPeatuhnA6Nh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc vecadd.cu"
      ],
      "metadata": {
        "id": "B8gcA_rP9Lrg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ellenörizzük ha megjelent a futtatható bináris program (`a.out`):"
      ],
      "metadata": {
        "id": "HBKgJTrFA-Yn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k0qF_LNk9P_I",
        "outputId": "e11a02f5-cb35-42f3-a0de-a6ed5f6beb7f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a.out  sample_data  vecadd.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Futtatás:"
      ],
      "metadata": {
        "id": "0GJCibQSBJer"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!./a.out"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lngC1HH79R7N",
        "outputId": "aa85bccf-2ecb-4ffc-bd76-c53c00275895"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a + b = 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feladatok\n",
        "\n",
        "1. Írjunk egy CUDA programot, mely a [`cudaError_t cudaGetDeviceCount (int * count)`](https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1g18808e54893cfcaafefeab31a73cc55f), [`cudaError_t cudaGetDeviceProperties (struct cudaDeviceProp * prop, int device )`](https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1g1bf9d625a931d657e08db2b4391170f0) függvények segítségével, kiírja a CUDA kompatibilis GPU főbb paramétereit.\n",
        "A jellemzőket tartalmazó `cudaDeviceProp` struktúra definíciója a következő:\n",
        "\n",
        "  ```cpp\n",
        "  struct cudaDeviceProp {\n",
        "                char name[256];\n",
        "                cudaUUID_t uuid;\n",
        "                size_t totalGlobalMem;\n",
        "                size_t sharedMemPerBlock;\n",
        "                int regsPerBlock;\n",
        "                int warpSize;\n",
        "                size_t memPitch;\n",
        "                int maxThreadsPerBlock;\n",
        "                int maxThreadsDim[3];\n",
        "                int maxGridSize[3];\n",
        "                int clockRate;\n",
        "                size_t totalConstMem;\n",
        "                int major;\n",
        "                int minor;\n",
        "                size_t textureAlignment;\n",
        "                size_t texturePitchAlignment;\n",
        "                int deviceOverlap;\n",
        "                int multiProcessorCount;\n",
        "                int kernelExecTimeoutEnabled;\n",
        "                int integrated;\n",
        "                int canMapHostMemory;\n",
        "                int computeMode;\n",
        "                int maxTexture1D;\n",
        "                int maxTexture1DMipmap;\n",
        "                int maxTexture1DLinear;\n",
        "                int maxTexture2D[2];\n",
        "                int maxTexture2DMipmap[2];\n",
        "                int maxTexture2DLinear[3];\n",
        "                int maxTexture2DGather[2];\n",
        "                int maxTexture3D[3];\n",
        "                int maxTexture3DAlt[3];\n",
        "                int maxTextureCubemap;\n",
        "                int maxTexture1DLayered[2];\n",
        "                int maxTexture2DLayered[3];\n",
        "                int maxTextureCubemapLayered[2];\n",
        "                int maxSurface1D;\n",
        "                int maxSurface2D[2];\n",
        "                int maxSurface3D[3];\n",
        "                int maxSurface1DLayered[2];\n",
        "                int maxSurface2DLayered[3];\n",
        "                int maxSurfaceCubemap;\n",
        "                int maxSurfaceCubemapLayered[2];\n",
        "                size_t surfaceAlignment;\n",
        "                int concurrentKernels;\n",
        "                int ECCEnabled;\n",
        "                int pciBusID;\n",
        "                int pciDeviceID;\n",
        "                int pciDomainID;\n",
        "                int tccDriver;\n",
        "                int asyncEngineCount;\n",
        "                int unifiedAddressing;\n",
        "                int memoryClockRate;\n",
        "                int memoryBusWidth;\n",
        "                int l2CacheSize;\n",
        "                int persistingL2CacheMaxSize;\n",
        "                int maxThreadsPerMultiProcessor;\n",
        "                int streamPrioritiesSupported;\n",
        "                int globalL1CacheSupported;\n",
        "                int localL1CacheSupported;\n",
        "                size_t sharedMemPerMultiprocessor;\n",
        "                int regsPerMultiprocessor;\n",
        "                int managedMemory;\n",
        "                int isMultiGpuBoard;\n",
        "                int multiGpuBoardGroupID;\n",
        "                int singleToDoublePrecisionPerfRatio;\n",
        "                int pageableMemoryAccess;\n",
        "                int concurrentManagedAccess;\n",
        "                int computePreemptionSupported;\n",
        "                int canUseHostPointerForRegisteredMem;\n",
        "                int cooperativeLaunch;\n",
        "                int cooperativeMultiDeviceLaunch;\n",
        "                int pageableMemoryAccessUsesHostPageTables;\n",
        "                int directManagedMemAccessFromHost;\n",
        "                int accessPolicyMaxWindowSize;\n",
        "            }\n",
        "   ```\n",
        "\n",
        "2. Írjunk egy \"Hello, World\" CUDA kernelt, melyben minden szál kiírja az [egyedi azonosítóját](https://blog.usejournal.com/cuda-thread-indexing-fb9910cba084). Hívjuk meg a kernelt különböző rács és blokk konfigurációkkal. Használjuk a [cudaError_t cudaDeviceSynchronize ( void )](https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1g10e20b05a95f638a4071a655503df25d) függvényt a kernel hívás bevárására.\n",
        "\n",
        "3. Futtasuk a két tömb összeadása példát.\n",
        "4. Készítsünk CUDA programot, amely egy vektort megszoroz egy konstans értékkel, majd megkeresi a vektor legnagyobb értékét.\n",
        "\n",
        "  **Specifikáció**:\n",
        "  - Hozzunk létre egy 100000 elemű, véletlenszámokat tartalmazó vektort\n",
        "  - A konstans szorzó értéke legyen 2.5\n",
        "  - Írjunk kernelt a vektor konstanssal való szorzásához\n",
        "  - A maximumot egyelőre a CPU oldalon keressük meg a szorzás után\n",
        "\n",
        "  **Lépések**:\n",
        "  1. Hozzunk létre és inicializáljunk egy vektort a host (CPU) oldalon\n",
        "  2. Foglaljunk memóriát a device (GPU) oldalon\n",
        "  3. Másoljuk az adatokat a host-ról a device-ra\n",
        "  4. Implementáljunk és indítsunk egy kernelt a vektor szorzásához\n",
        "  5. Másoljuk vissza az eredményt a device-ról a host-ra\n",
        "  6. Keressük meg a vektor legnagyobb értékét a CPU-n\n",
        "  7. Írjuk ki az eredményt és szabadítsuk fel az erőforrásokat\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "xnd_G4H09VNY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Feladat 1."
      ],
      "metadata": {
        "id": "9Dk41dnipnHk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile feladat1.cu\n",
        "\n",
        "#include <cuda.h>\n",
        "#include <iostream>\n",
        "\n",
        "using namespace std;\n",
        "\n",
        "int main(int argc, char** argv)\n",
        "{\n",
        "    int deviceCounter;\n",
        "    auto error = cudaGetDeviceCount(&deviceCounter);\n",
        "\n",
        "    if(error != 0){\n",
        "      cout << \"No CUDA compatible devices found\" << endl;\n",
        "      return 0;\n",
        "    }\n",
        "    cout << deviceCounter << endl;\n",
        "\n",
        "    struct cudaDeviceProp prop;\n",
        "\n",
        "\n",
        "     for(int i = 0; i < deviceCounter; i++){\n",
        "        auto x = cudaGetDeviceProperties (&prop, i);\n",
        "\n",
        "        cout<<\" Név: \" << prop.name << endl;\n",
        "        cout << \"  Számítási képesség: \" << prop.major << \".\" << prop.minor << endl;\n",
        "        cout << \"  Többszálú processzorok száma: \" << prop.multiProcessorCount << endl;\n",
        "        cout << \"  Órajel (MHz): \" << prop.clockRate  << endl;\n",
        "        cout << \"  Összes globális memória: \" << prop.totalGlobalMem << endl;\n",
        "     }\n",
        "\n",
        "     return 0;\n",
        "\n",
        "}"
      ],
      "metadata": {
        "id": "m110qJJ0QhKc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "177e4fed-b462-41da-efb9-3f30811a8ef2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting feladat1.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -arch=sm_75 feladat1.cu -o feladat1"
      ],
      "metadata": {
        "id": "BHOaQhEjpwaV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./feladat1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "topD65ITr5qL",
        "outputId": "e20fa839-5aff-4505-9169-fa4552be7e3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            " Név: Tesla T4\n",
            "  Számítási képesség: 7.5\n",
            "  Többszálú processzorok száma: 40\n",
            "  Órajel (MHz): 1590000\n",
            "  Összes globális memória: 15828320256\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Feladat 2."
      ],
      "metadata": {
        "id": "emwscZw1vqUq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile feladat2.cu\n",
        "\n",
        "#include \"cuda.h\"\n",
        "#include <iostream>\n",
        "\n",
        "using namespace std;\n",
        "\n",
        "__global__ void printHelloWorld() {\n",
        "\n",
        "      int globalID = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\n",
        "      printf(\"BlockDim: %d \\n\", blockDim.x);\n",
        "      printf(\"BlockIdx: %d \\n\", blockIdx.x);\n",
        "      printf(\"ThreadIdx: %d \\n\", threadIdx.x);\n",
        "\n",
        "      printf(\"GlobalId: %d \\n\", globalID);\n",
        "\n",
        "      printf(\"\\n\\n Hello World \\n\");\n",
        "\n",
        "    //cout << \"BlockDim \" << blockDim.x << endl;\n",
        "    //cout << \"BlockIdx \" << blockIdx.x << endl;\n",
        "    //cout << \"ThreadIdx \" << threadIdx.x << endl;\n",
        "\n",
        "    //cout << endl << endl << \"Hello World\" << endl;\n",
        "}\n",
        "\n",
        "int main(int argc, char** argv){\n",
        "\n",
        "  printHelloWorld<<<2, 5>>>();\n",
        "\n",
        "  cudaDeviceSynchronize();\n",
        "\n",
        "  return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "avC-3SfKvrUr",
        "outputId": "7f74c9c0-1a5f-4b96-cd8f-a073bddbd1f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting feladat2.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -arch=sm_75 feladat2.cu -o feladat2"
      ],
      "metadata": {
        "id": "_sxPYdpCxDa6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./feladat2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zVkQpxyXxD4L",
        "outputId": "1d6bfdef-d80a-45b7-effc-ee437029cb29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BlockDim: 5 \n",
            "BlockDim: 5 \n",
            "BlockDim: 5 \n",
            "BlockDim: 5 \n",
            "BlockDim: 5 \n",
            "BlockDim: 5 \n",
            "BlockDim: 5 \n",
            "BlockDim: 5 \n",
            "BlockDim: 5 \n",
            "BlockDim: 5 \n",
            "BlockIdx: 1 \n",
            "BlockIdx: 1 \n",
            "BlockIdx: 1 \n",
            "BlockIdx: 1 \n",
            "BlockIdx: 1 \n",
            "BlockIdx: 0 \n",
            "BlockIdx: 0 \n",
            "BlockIdx: 0 \n",
            "BlockIdx: 0 \n",
            "BlockIdx: 0 \n",
            "ThreadIdx: 0 \n",
            "ThreadIdx: 1 \n",
            "ThreadIdx: 2 \n",
            "ThreadIdx: 3 \n",
            "ThreadIdx: 4 \n",
            "ThreadIdx: 0 \n",
            "ThreadIdx: 1 \n",
            "ThreadIdx: 2 \n",
            "ThreadIdx: 3 \n",
            "ThreadIdx: 4 \n",
            "GlobalId: 5 \n",
            "GlobalId: 6 \n",
            "GlobalId: 7 \n",
            "GlobalId: 8 \n",
            "GlobalId: 9 \n",
            "GlobalId: 0 \n",
            "GlobalId: 1 \n",
            "GlobalId: 2 \n",
            "GlobalId: 3 \n",
            "GlobalId: 4 \n",
            "\n",
            "\n",
            " Hello World \n",
            "\n",
            "\n",
            " Hello World \n",
            "\n",
            "\n",
            " Hello World \n",
            "\n",
            "\n",
            " Hello World \n",
            "\n",
            "\n",
            " Hello World \n",
            "\n",
            "\n",
            " Hello World \n",
            "\n",
            "\n",
            " Hello World \n",
            "\n",
            "\n",
            " Hello World \n",
            "\n",
            "\n",
            " Hello World \n",
            "\n",
            "\n",
            " Hello World \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Feladat 3."
      ],
      "metadata": {
        "id": "F16fBIQT1867"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile feladat3.cu\n",
        "\n",
        "# include <stdio.h>\n",
        "# include <cuda_runtime.h>\n",
        "\n",
        "// GPU kernel - minden szál egy elemet dolgoz fel\n",
        "__global__ void vectorAdd(int *a, int *b, int *c, int n) {\n",
        "    int i = blockDim.x * blockIdx.x + threadIdx.x;\n",
        "    if (i < n) {\n",
        "        c[i] = a[i] + b[i];\n",
        "    }\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    int n = 1000;\n",
        "    int size = n * sizeof(int);\n",
        "\n",
        "    // Host memória foglalása\n",
        "    int *h_a = (int *)malloc(size);\n",
        "    int *h_b = (int *)malloc(size);\n",
        "    int *h_c = (int *)malloc(size);\n",
        "\n",
        "    // Vektorok inicializálása\n",
        "    for (int i = 0; i < n; i++) {\n",
        "        h_a[i] = i;\n",
        "        h_b[i] = i;\n",
        "    }\n",
        "\n",
        "    // Device memória foglalása\n",
        "    int *d_a, *d_b, *d_c;\n",
        "    cudaMalloc(&d_a, size);\n",
        "    cudaMalloc(&d_b, size);\n",
        "    cudaMalloc(&d_c, size);\n",
        "\n",
        "    // Adatok másolása a host-ról a device-ra\n",
        "    cudaMemcpy(d_a, h_a, size, cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_b, h_b, size, cudaMemcpyHostToDevice);\n",
        "\n",
        "    // Kernel indítása 256 szállal blokkonként\n",
        "    int threadsPerBlock = 256;\n",
        "    int blocksPerGrid = (n + threadsPerBlock - 1) / threadsPerBlock;\n",
        "    vectorAdd<<<blocksPerGrid, threadsPerBlock>>>(d_a, d_b, d_c, n);\n",
        "\n",
        "    // Eredmény visszamásolása a device-ról a host-ra\n",
        "    cudaMemcpy(h_c, d_c, size, cudaMemcpyDeviceToHost);\n",
        "\n",
        "    // Eredmény ellenőrzése\n",
        "    for (int i = 0; i < 10; i++) {\n",
        "        printf(\"%d + %d = %d\\n\", h_a[i], h_b[i], h_c[i]);\n",
        "    }\n",
        "\n",
        "    // Memória felszabadítása\n",
        "    cudaFree(d_a);\n",
        "    cudaFree(d_b);\n",
        "    cudaFree(d_c);\n",
        "    free(h_a);\n",
        "    free(h_b);\n",
        "    free(h_c);\n",
        "\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4NIF1r5b1-iL",
        "outputId": "2e8fe190-be23-4f23-bf9e-657e2baff59b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing feladat3.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -arch=sm_75 feladat3.cu -o feladat3"
      ],
      "metadata": {
        "id": "fdfl4F8E2AKZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./feladat3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pcw3j3d-2AzN",
        "outputId": "9410a795-9164-4df3-b45f-7ab51c24ac33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 + 0 = 0\n",
            "1 + 1 = 2\n",
            "2 + 2 = 4\n",
            "3 + 3 = 6\n",
            "4 + 4 = 8\n",
            "5 + 5 = 10\n",
            "6 + 6 = 12\n",
            "7 + 7 = 14\n",
            "8 + 8 = 16\n",
            "9 + 9 = 18\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Feladat 4"
      ],
      "metadata": {
        "id": "Hcva4RPX24RV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile feladat4.cu\n",
        "\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <time.h>\n",
        "#include <cuda_runtime.h>\n",
        "\n",
        "__global__ void vectorScalarMultiply(float *array, float value, int n) {\n",
        "    int i = blockDim.x * blockIdx.x + threadIdx.x;\n",
        "\n",
        "    if(i <n){\n",
        "      array[i] = array[i] * value;\n",
        "    }\n",
        "}\n",
        "\n",
        "\n",
        "int main(){\n",
        "\n",
        "  int n = 100000;\n",
        "\n",
        "  float* array = new float[n];\n",
        "\n",
        "  srand(time(0));\n",
        "\n",
        "  for(int i = 0; i < n; i++){\n",
        "    array[i] = rand() / (float)RAND_MAX * 100;\n",
        "  }\n",
        "\n",
        "  int size = n * sizeof(float);\n",
        "\n",
        "  float *d_array;\n",
        "  cudaMalloc(&d_array, size);\n",
        "  cudaMemcpy(d_array, array, size, cudaMemcpyHostToDevice);\n",
        "\n",
        "  float mulitplyValue = 2.5;\n",
        "\n",
        "  int threadsPerBlock = 256;\n",
        "  int blocksPerGrid = (n + threadsPerBlock - 1) / threadsPerBlock;\n",
        "\n",
        "  vectorScalarMultiply<<<blocksPerGrid, threadsPerBlock>>>(d_array, mulitplyValue, n);\n",
        "\n",
        "  cudaMemcpy(array, d_array, size, cudaMemcpyDeviceToHost);\n",
        "\n",
        "  float maxi = -1;\n",
        "\n",
        "  for(int i=0; i<n; i++){\n",
        "    if(array[i] > maxi){\n",
        "      maxi = array[i];\n",
        "    }\n",
        "  }\n",
        "\n",
        "  printf(\"Maximum: %f\", maxi);\n",
        "\n",
        "  cudaFree(d_array);\n",
        "  free(array);\n",
        "\n",
        "\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uVmGas3v25fb",
        "outputId": "a86eaf8a-1125-4490-8502-7e45909d8747"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting feladat4.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -arch=sm_75 feladat4.cu -o feladat4"
      ],
      "metadata": {
        "id": "5h7thD8y2_3R"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./feladat4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9H5tkwgV3AYV",
        "outputId": "846e83e9-2982-4b42-c301-ad3054d35a76"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Maximum: 249.994949"
          ]
        }
      ]
    }
  ]
}